{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "square-longer",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "\n",
    "## VQ-VAE (20 points) \n",
    "\n",
    "You will train a [VQ-VAE](https://arxiv.org/abs/1711.00937) on CIFAR-10 and SVHN. If you are confused on how the VQ-VAE works, you may find [Lilian Weng's blogpost](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html#vq-vae-and-vq-vae-2) to be useful.\n",
    "\n",
    "You may experiment with different hyperparameters and architecture designs, but the following designs for the VQ-VAE architecture may be useful.\n",
    "\n",
    "```\n",
    "conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "transpose_conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "linear(in_dim, out_dim)\n",
    "batch_norm2d(dim)\n",
    "\n",
    "residual_block(dim)\n",
    "    batch_norm2d(dim)\n",
    "    relu()\n",
    "    conv2d(dim, dim, 3, 1, 1)\n",
    "    batch_norm2d(dim)\n",
    "    relu()\n",
    "    conv2d(dim, dim, 1, 1, 0)\n",
    "\n",
    "Encoder\n",
    "    conv2d(3, 256, 4, 2, 1) 16 x 16\n",
    "    batch_norm2d(256)\n",
    "    relu()\n",
    "    conv2d(256, 256, 4, 2, 1) 8 x 8\n",
    "    residual_block(256)\n",
    "    residual_block(256)\n",
    "\n",
    "Decoder\n",
    "    residual_block(256)\n",
    "    residual_block(256)\n",
    "    batch_norm2d(256)\n",
    "    relu()\n",
    "    transpose_conv2d(256, 256, 4, 2, 1) 16 x 16\n",
    "    batch_norm2d(256)\n",
    "    relu()\n",
    "    transpose_conv2d(256, 3, 4, 2, 1) 32 x 32\n",
    "```\n",
    "\n",
    "A few other tips:\n",
    "*   Use a codebook with $K = 128$ latents each with a $D = 256$ dimensional embedding vector\n",
    "*   You should initialize each element in your $K\\times D$ codebook to be uniformly random in $[-1/K, 1/K]$\n",
    "*   Use batch size 128 with a learning rate of $10^{-3}$ and an Adam optimizer\n",
    "*   Center and scale your images to $[-1, 1]$\n",
    "*   Supposing that $z_e(x)$ is the encoder output, and $z_q(x)$ is the quantized output using the codebook, you can implement the straight-through estimator as follows (where below is fed into the decoder): \n",
    "  * `(z_q(x) - z_e(x)).detach() + z_e(x)` in Pytorch\n",
    "  * `tf.stop_gradient(z_q(x) - z_e(x)) + z_e(x)` in Tensorflow.\n",
    "\n",
    "In addition to training the VQ-VAE, you will also need to train a PixelCNN prior on the categorical latents in order to sample. For your architecture, you may find the following useful:\n",
    "*   Since the input is a 2D grid of discrete values, you should have an input (learned) embedding layer to map the discrete values to embeddings of length $64$\n",
    "*   Use a single Type A masked convolutions followed by 10-15 residual blocks, and $2$ $1\\times 1$ convolutions of $512$ and $K$ channels respectively.\n",
    "*   You may find normalization methods (e.g. BatchNorm, LayerNorm) to be useful. But do not forget about autoregressive property in PixelCNN, use normalization carefully!\n",
    "*   Use batch size 128 with a learning rate of $10^{-3}$ and an Adam optimizer\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the average loss of the training data (per minibatch) and test data (for your entire test set) **for both your VQ-VAE and PixelCNN prior**\n",
    "2. Report the final test set performances of your final models\n",
    "3. 100 samples from your trained VQ-VAE and PixelCNN prior\n",
    "4. 50 real-image / reconstruction pairs (for some $x$, encode and then decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-proposal",
   "metadata": {},
   "source": [
    "## PixelVAE (10 points)\n",
    "Implement and train a VAE with a PixelCNN decoder, and get it to produce good samples but not ignore latents. It may help to reference the latent variable model slides on techniques to prevent posterior collapse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
